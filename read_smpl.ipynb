{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e543a98-da41-4101-86d3-bd6a495c9cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SMPLlayer()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. load SMPL model\n",
    "import easymocap\n",
    "from easymocap.smplmodel import load_model\n",
    "load_model\n",
    "load_model(gender='male', use_cuda=True, model_type='smpl', skel_type='body25', device=None, model_path='data/smpl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e3d213d-971e-4ef6-ae55-eb8a5040fb22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m infos \u001b[38;5;241m=\u001b[39m read_smpl(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmpl/smpl/000000.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 2. compute joints\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m joints \u001b[38;5;241m=\u001b[39m body_model(return_verts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43minfo\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 3. compute vertices\u001b[39;00m\n\u001b[1;32m     10\u001b[0m vertices \u001b[38;5;241m=\u001b[39m body_model(return_verts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minfo)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'info' is not defined"
     ]
    }
   ],
   "source": [
    "import easymocap.dataset\n",
    "from easymocap.dataset.base import read_smpl\n",
    "from easymocap.smplmodel import body_model\n",
    "# 1. load parameters\n",
    "#read_smpl('smpl/smpl/')\n",
    "infos = read_smpl('smpl/smpl/000000.json')\n",
    "# 2. compute joints\n",
    "joints = body_model(return_verts=False, return_tensor=False, **info)[0]\n",
    "# 3. compute vertices\n",
    "vertices = body_model(return_verts=True, return_tensor=False, **info)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26413240-1114-4de1-b8b6-09557c0400b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e08d1f55-43f8-4c4c-b817-805f35d38fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load model smpl/male]\n",
      "[[ 0.11139575  0.48919022  1.4449916 ]\n",
      " [ 0.20591721  0.36942452  1.2740303 ]\n",
      " [ 0.15142226  0.22553657  1.2818601 ]\n",
      " [ 0.15584391 -0.06200153  1.2105396 ]\n",
      " [ 0.17647465 -0.32680508  1.1853908 ]\n",
      " [ 0.2512911   0.511618    1.2584592 ]\n",
      " [ 0.45951337  0.7273189   1.2238953 ]\n",
      " [ 0.64015067  0.9254594   1.2383199 ]\n",
      " [ 0.6425178   0.19341624  1.0618515 ]\n",
      " [ 0.6012698   0.098171    1.0610065 ]\n",
      " [ 0.97919786 -0.07087687  0.90071225]\n",
      " [ 1.3090551  -0.22479942  0.69749177]\n",
      " [ 0.6793677   0.2900664   1.0648882 ]\n",
      " [ 1.0640378   0.18388706  0.88186395]\n",
      " [ 1.4130931   0.08554173  0.6720828 ]\n",
      " [ 0.07736829  0.4635222   1.4585067 ]\n",
      " [ 0.07789224  0.5093138   1.4250071 ]\n",
      " [ 0.04988685  0.36381146  1.4152138 ]\n",
      " [ 0.05391949  0.49543196  1.3264413 ]\n",
      " [ 1.5331894   0.08411427  0.813334  ]\n",
      " [ 1.5270165   0.11155879  0.7817917 ]\n",
      " [ 1.4292283   0.07240571  0.6308597 ]\n",
      " [ 1.4050813  -0.31211844  0.83468664]\n",
      " [ 1.3828192  -0.32648394  0.80404687]\n",
      " [ 1.3286453  -0.22256306  0.6552981 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n{'poses': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\\n        0., 0., 0., 0., 0., 0., 0., 0.]]), 'shapes': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'Rh': array([[0., 0., 0.]]), 'Th': array([[0., 0., 0.]])}\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pyrender # first import the pyrender\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from easymocap.mytools.reader import read_smpl\n",
    "import os\n",
    "import json\n",
    "from easymocap.dataset.base import MVBase\n",
    "from easymocap.dataset.config import CONFIG\n",
    "# 0. load SMPL model\n",
    "from easymocap.smplmodel import load_model\n",
    "from os.path import join\n",
    "from easymocap.mytools.cmd_loader import load_parser\n",
    "from easymocap.config import Config, load_object\n",
    "\n",
    "#parser = load_parser()\n",
    "#parser.add_argument('--gender', type=str, default='neutral', choices=['male', 'female', 'neutral'])\n",
    "#parser.add_argument('--model', type=str, default='smpl', choices=['none', 'smpl', 'smplx'])\n",
    "#args = parser.parse_args()\n",
    "\n",
    "#body_model = load_model(args.gender, model_type=args.model)\n",
    "# 1. load parameters\n",
    "nf=0\n",
    "step=1\n",
    "smpl_output_path='smpl/smpl'\n",
    "def read_json(path):\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def read_smpl(nf):\n",
    "        outname = join(smpl_output_path, '{:06d}.json'.format(nf))\n",
    "        assert os.path.exists(outname), outname\n",
    "        datas = read_json(outname)\n",
    "        outputs = []\n",
    "        for data in datas:\n",
    "            for key in ['Rh', 'Th', 'poses', 'shapes']:\n",
    "                data[key] = np.array(data[key])\n",
    "            outputs.append(data)\n",
    "        return outputs\n",
    "infos = read_smpl(nf*step)\n",
    "#print(infos)\n",
    "'''\n",
    "[{'id': 0, 'Rh': array([[ 1.279, -1.263, -1.197]]), 'Th': array([[0.42 , 0.285, 1.168]]), 'poses': array([[ 0.   ,  0.   ,  0.   , -0.067,  0.093,  0.162, -0.147, -0.082,\n",
    "        -0.096,  0.   ,  0.   , -0.   ,  0.022,  0.044, -0.073,  0.094,\n",
    "        -0.049,  0.042, -0.   ,  0.   ,  0.   , -0.043,  0.136, -0.004,\n",
    "        -0.004, -0.144,  0.024,  0.034,  0.   ,  0.   , -0.   ,  0.   ,\n",
    "        -0.   ,  0.   ,  0.   , -0.   , -0.288,  0.39 ,  0.043,  0.   ,\n",
    "         0.   ,  0.   , -0.   ,  0.   ,  0.001,  0.281,  0.353,  0.019,\n",
    "        -0.03 , -0.1  , -0.368, -0.027,  0.071,  0.426, -0.018, -0.158,\n",
    "         0.065, -0.01 ,  0.091,  0.013, -0.   ,  0.   ,  0.   ,  0.   ,\n",
    "        -0.   , -0.   , -0.   , -0.   , -0.   , -0.   , -0.   ,  0.   ]]), 'shapes': array([[ 0.188, -0.178,  0.054,  0.178,  0.027,  0.035, -0.021, -0.022,\n",
    "         0.018, -0.015]])}]\n",
    "'''\n",
    "for info in infos:\n",
    "    #config = Config.load(args.cfg)\n",
    "    body_model=load_model('male','smpl')\n",
    "    #body_model = load_object(config.module, config.args)\n",
    "# 2. compute joints\n",
    "    #params = body_model.init_params(1)\n",
    "    pose=info[\"poses\"]\n",
    "    Rh=info[\"Rh\"]\n",
    "    Th=info[\"Th\"]\n",
    "    shapes=info[\"shapes\"]\n",
    "    #global_orient = pose[:, :3]\n",
    "#taking the global orientation of the body (the first 3 columns of the pose matrix)\n",
    "    #body_pose = pose[:, 3:]\n",
    "    body_pose=pose\n",
    "#taking the body pose (from the 4th columns to the end of the pose matrix)\n",
    "    body_params = {\n",
    "    'poses':body_pose,\n",
    "    'shapes': shapes,\n",
    "    'Rh':Th,\n",
    "    'Th':Th\n",
    "    #'transl': trans\n",
    "    }\n",
    "    #smpl_model.forward(**body_params)\n",
    "\n",
    "#for info in infos:\n",
    "    #get parameter \n",
    "    #print(data)\n",
    "    \n",
    "\n",
    "    joints = body_model(return_verts=False, return_tensor=False, **body_params)[0]\n",
    "    print(joints)\n",
    "# 3. compute vertices\n",
    "#vertices = body_model(return_verts=True, return_tensor=False, **infos)[0]\n",
    "'''\n",
    "{'poses': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0.]]), 'shapes': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'Rh': array([[0., 0., 0.]]), 'Th': array([[0., 0., 0.]])}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21ce832b-51d4-4f14-a3b0-8cf64d7a3f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'Rh': array([[ 1.279, -1.263, -1.197]]),\n",
       " 'Th': array([[0.42 , 0.285, 1.168]]),\n",
       " 'poses': array([[ 0.   ,  0.   ,  0.   , -0.067,  0.093,  0.162, -0.147, -0.082,\n",
       "         -0.096,  0.   ,  0.   , -0.   ,  0.022,  0.044, -0.073,  0.094,\n",
       "         -0.049,  0.042, -0.   ,  0.   ,  0.   , -0.043,  0.136, -0.004,\n",
       "         -0.004, -0.144,  0.024,  0.034,  0.   ,  0.   , -0.   ,  0.   ,\n",
       "         -0.   ,  0.   ,  0.   , -0.   , -0.288,  0.39 ,  0.043,  0.   ,\n",
       "          0.   ,  0.   , -0.   ,  0.   ,  0.001,  0.281,  0.353,  0.019,\n",
       "         -0.03 , -0.1  , -0.368, -0.027,  0.071,  0.426, -0.018, -0.158,\n",
       "          0.065, -0.01 ,  0.091,  0.013, -0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         -0.   , -0.   , -0.   , -0.   , -0.   , -0.   , -0.   ,  0.   ]]),\n",
       " 'shapes': array([[ 0.188, -0.178,  0.054,  0.178,  0.027,  0.035, -0.021, -0.022,\n",
       "          0.018, -0.015]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8a1958b-1116-40c5-8b58-63773863a6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.5555682e-02  4.4909945e-01  7.9092458e-02]\n",
      " [-7.4490556e-04  2.5310194e-01 -1.1841999e-02]\n",
      " [-1.5458582e-01  2.5440803e-01 -3.7168497e-03]\n",
      " [-4.2009538e-01  1.2351385e-01 -1.6195312e-02]\n",
      " [-6.5849251e-01  7.9760775e-03  1.5377577e-02]\n",
      " [ 1.4814927e-01  2.5519738e-01 -3.0453036e-02]\n",
      " [ 4.2556655e-01  1.3837624e-01 -8.7610818e-03]\n",
      " [ 6.7646176e-01  6.1096698e-02  4.7603920e-02]\n",
      " [-2.7872398e-03 -2.6246354e-01  1.6564628e-02]\n",
      " [-1.0653418e-01 -2.6010606e-01  1.4377767e-02]\n",
      " [-1.2381339e-01 -7.0110673e-01  6.2554024e-02]\n",
      " [-1.4481308e-01 -1.1172613e+00  4.9484272e-02]\n",
      " [ 1.0063827e-01 -2.5972328e-01  1.8576119e-02]\n",
      " [ 1.4426599e-01 -6.9610876e-01  3.8759504e-02]\n",
      " [ 1.8200384e-01 -1.1128699e+00  1.8620286e-02]\n",
      " [ 3.9121915e-02  4.7495845e-01  8.0899879e-02]\n",
      " [ 8.1864201e-02  4.7413602e-01  4.3593220e-02]\n",
      " [-6.3678339e-02  4.4495064e-01  4.7682796e-02]\n",
      " [ 6.0110971e-02  4.4396400e-01 -5.1795870e-02]\n",
      " [ 2.2507758e-01 -1.1473457e+00  1.9563192e-01]\n",
      " [ 2.4829671e-01 -1.1477677e+00  1.6032024e-01]\n",
      " [ 1.7577057e-01 -1.1494714e+00 -8.8336132e-03]\n",
      " [-1.9044258e-01 -1.1619544e+00  2.2721596e-01]\n",
      " [-2.1201947e-01 -1.1624191e+00  1.9293791e-01]\n",
      " [-1.3548596e-01 -1.1521120e+00  2.0030636e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87eb0f7b-3558-4a0b-97ac-4b5c446a11a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(joints)\n",
    "#np.shape(info[\"poses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "382aa695-e5d7-48c2-b3bb-dd7afe1d08fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'Rh': array([[ 1.279, -1.263, -1.197]]),\n",
       " 'Th': array([[0.42 , 0.285, 1.168]]),\n",
       " 'poses': array([[ 0.   ,  0.   ,  0.   , -0.067,  0.093,  0.162, -0.147, -0.082,\n",
       "         -0.096,  0.   ,  0.   , -0.   ,  0.022,  0.044, -0.073,  0.094,\n",
       "         -0.049,  0.042, -0.   ,  0.   ,  0.   , -0.043,  0.136, -0.004,\n",
       "         -0.004, -0.144,  0.024,  0.034,  0.   ,  0.   , -0.   ,  0.   ,\n",
       "         -0.   ,  0.   ,  0.   , -0.   , -0.288,  0.39 ,  0.043,  0.   ,\n",
       "          0.   ,  0.   , -0.   ,  0.   ,  0.001,  0.281,  0.353,  0.019,\n",
       "         -0.03 , -0.1  , -0.368, -0.027,  0.071,  0.426, -0.018, -0.158,\n",
       "          0.065, -0.01 ,  0.091,  0.013, -0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         -0.   , -0.   , -0.   , -0.   , -0.   , -0.   , -0.   ,  0.   ]]),\n",
       " 'shapes': array([[ 0.188, -0.178,  0.054,  0.178,  0.027,  0.035, -0.021, -0.022,\n",
       "          0.018, -0.015]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e9e0b-6556-4866-91cc-93f3bbad39f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pytorch3d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m aa\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.067\u001b[39m,  \u001b[38;5;241m0.093\u001b[39m,  \u001b[38;5;241m0.162\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m rot_mat \u001b[38;5;241m=\u001b[39m \u001b[43mpytorch3d\u001b[49m\u001b[38;5;241m.\u001b[39mtransfroms\u001b[38;5;241m.\u001b[39maxis_angle_to_matrix(aa)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Euler angles\u001b[39;00m\n\u001b[1;32m      8\u001b[0m euler \u001b[38;5;241m=\u001b[39m pytorch3d\u001b[38;5;241m.\u001b[39mtransfroms\u001b[38;5;241m.\u001b[39mmatrix_to_euler_angles(rot_mat, convention)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pytorch3d' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "aa=np.array([-0.067,  0.093,  0.162])\n",
    "\n",
    "\n",
    "rot_mat = pytorch3d.transfroms.axis_angle_to_matrix(aa)\n",
    "\n",
    "# Euler angles\n",
    "euler = pytorch3d.transfroms.matrix_to_euler_angles(rot_mat, convention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995d1b26-0d66-4bf8-b69a-2ab7cd05828f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pytorch3d' has no attribute 'transforms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch3d\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpytorch3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pytorch3d' has no attribute 'transforms'"
     ]
    }
   ],
   "source": [
    "import pytorch3d\n",
    "pytorch3d.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a98aac-c71b-426c-88e3-d97eafc97684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch3d\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e13d20f-bd40-4e88-a5fe-a0a078f210df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libc10.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m  \u001b[38;5;21;01mpytorch3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _C\n",
      "\u001b[0;31mImportError\u001b[0m: libc10.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from  pytorch3d import _C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f22dff12-afd8-41e1-be8a-4bdc8f4f3368",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'transforms' from 'pytorch3d' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'transforms' from 'pytorch3d' (unknown location)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch3d import transforms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
